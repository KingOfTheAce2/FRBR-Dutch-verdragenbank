# .github/workflows/crawl.yml
# This workflow automates the process of crawling the Verdragenbank repository.

name: Verdragenbank Crawler

on:
  # Allows manual triggering of the workflow from the Actions tab in GitHub.
  workflow_dispatch:
  # Schedules the workflow to run at 02:00 on every Sunday.
  schedule:
    - cron: '0 2 * * 0'

permissions:
  contents: write

jobs:
  crawl:
    runs-on: ubuntu-latest
    steps:
      - name: Check out repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          # If xmltodict is not in requirements.txt, add it here or to the file
          pip install xmltodict huggingface_hub git-lfs

      - name: Run crawler
        run: |
            if [ "$GITHUB_EVENT_NAME" = "workflow_dispatch" ]; then
            python crawler.py --reset
          else
            python crawler.py
          fi

      - name: Commit and push if it changed
        run: |
          git config --global user.name "Verdragenbank Crawler Bot"
          git config --global user.email "crawler-bot@users.noreply.github.com"
          git add data/ .last_update
          # Commit only if there are changes
          git diff --staged --quiet || git commit -m "Weekly Verdragenbank data update"
          git push

      - name: Upload data to Hugging Face
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
          HF_DATASET_REPO: ${{ secrets.HF_DATASET_REPO }}
        run: |
          # The pip install for huggingface_hub and git-lfs can be moved to Install dependencies step
          # if not already there, for better organization.
          # For a single file, the `crawler` directory structure is gone.
          # The git lfs install should be done only once.
          git lfs install
          git clone https://huggingface.co/datasets/${HF_DATASET_REPO} hf-dataset
          cd hf-dataset
          git lfs track "*.jsonl"
          git add .gitattributes
          git commit -m "Track JSONL shards via Git LFS" || true
          cd ..
          cp data/*.jsonl hf-dataset/ || true
          cd hf-dataset
          git add .
          git commit -m "Update dataset from crawler run" || echo "No changes"
          git push https://user:${HF_TOKEN}@huggingface.co/datasets/${HF_DATASET_REPO} HEAD
